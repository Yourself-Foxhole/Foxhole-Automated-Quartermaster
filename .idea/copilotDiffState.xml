<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/data/db/materials.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/data/db/materials.py" />
              <option name="originalContent" value="from enum import Enum&#10;&#10;class Material(Enum):&#10;    BMAT = &quot;Basic Material&quot;&#10;    RMAT = &quot;Refined Material&quot;&#10;    EMAT = &quot;Explosive Powder&quot;&#10;    HEMAT = &quot;High Explosive Powder&quot;&#10;    PCMAT = &quot;Processed Construction Material&quot;&#10;    CMAT = &quot;Construction Material&quot;&#10;    AMAT1 = &quot;Assembly Material I&quot;&#10;    AMAT2 = &quot;Assembly Material II&quot;&#10;    AMAT3 = &quot;Assembly Material III&quot;&#10;    AMAT4 = &quot;Assembly Material IV&quot;&#10;    AMAT5 = &quot;Assembly Material V&quot;&#10;    RARE = &quot;Rare Alloy&quot;&#10;    HULL_SEGMENT = &quot;Naval Hull Segment&quot;&#10;    SHELL_PLATING = &quot;Naval Shell Plating&quot;&#10;    TURB_COMP = &quot;Naval Turbine Components&quot;&#10;&#10;class RawResource(Enum):&#10;    ALUMINUM = &quot;Aluminum&quot;&#10;    SALVAGE = &quot;Salvage&quot;&#10;    COPPER = &quot;Copper&quot;&#10;    COAL = &quot;Coal&quot;&#10;    SULFUR = &quot;Sulfur&quot;&#10;    IRON = &quot;Iron&quot;&#10;    COMPONENTS = &quot;Components&quot;&#10;" />
              <option name="updatedContent" value="from enum import Enum&#10;&#10;class Material(Enum):&#10;    BMAT = &quot;Basic Material&quot;&#10;    RMAT = &quot;Refined Material&quot;&#10;    EMAT = &quot;Explosive Powder&quot;&#10;    HEMAT = &quot;High Explosive Powder&quot;&#10;    PCMAT = &quot;Processed Construction Material&quot;&#10;    CMAT = &quot;Construction Material&quot;&#10;    AMAT1 = &quot;Assembly Material I&quot;&#10;    AMAT2 = &quot;Assembly Material II&quot;&#10;    AMAT3 = &quot;Assembly Material III&quot;&#10;    AMAT4 = &quot;Assembly Material IV&quot;&#10;    AMAT5 = &quot;Assembly Material V&quot;&#10;    RARE = &quot;Rare Alloy&quot;&#10;    HULL_SEGMENT = &quot;Naval Hull Segment&quot;&#10;    SHELL_PLATING = &quot;Naval Shell Plating&quot;&#10;    TURB_COMP = &quot;Naval Turbine Components&quot;&#10;&#10;class RawResource(Enum):&#10;    ALUMINUM = &quot;Aluminum&quot;&#10;    SALVAGE = &quot;Salvage&quot;&#10;    COPPER = &quot;Copper&quot;&#10;    COAL = &quot;Coal&quot;&#10;    SULFUR = &quot;Sulfur&quot;&#10;    IRON = &quot;Iron&quot;&#10;    COMPONENTS = &quot;Components&quot;&#10;&#10;class ResourceField(Enum):&#10;    COAL_FIELD = &quot;Coal Field&quot;&#10;    COMPONENT_FIELD = &quot;Component Field&quot;&#10;    OIL_FIELD = &quot;Oil Field&quot;&#10;    SALVAGE_FIELD = &quot;Salvage Field&quot;&#10;    SULFUR_FIELD = &quot;Sulfur Field&quot;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/data/static-game-data/db_models.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/data/static-game-data/db_models.py" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/services/inventory/order.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/services/inventory/order.py" />
              <option name="originalContent" value="from typing import Optional&#10;from services.inventory.inventory_graph import InventoryNode&#10;&#10;class Order:&#10;    def __init__(self, item: str, quantity: int, source: InventoryNode, target: InventoryNode, status: str = &quot;pending&quot;, created_at: Optional[float] = None):&#10;        self.item = item&#10;        self.quantity = quantity&#10;        self.source = source&#10;        self.target = target&#10;        self.status = status  # e.g., 'pending', 'in_transit', 'fulfilled', 'cancelled'&#10;        self.created_at = created_at&#10;        self.updated_at = created_at&#10;&#10;    def update_status(self, new_status: str, timestamp: Optional[float] = None):&#10;        self.status = new_status&#10;        if timestamp:&#10;            self.updated_at = timestamp&#10;&#10;    def __repr__(self):&#10;        return f&quot;&lt;Order {self.item} x{self.quantity} {self.source.node_id}-&gt;{self.target.node_id} status={self.status}&gt;&quot;&#10;&#10;" />
              <option name="updatedContent" value="from typing import Optional&#10;from services.inventory.inventory_graph import InventoryNode&#10;&#10;class Order:&#10;    def __init__(self, item: str, quantity: int, source: InventoryNode, target: InventoryNode, status: str = &quot;pending&quot;, created_at: Optional[float] = None, order_type: str = &quot;production&quot;, blocking_resources: Optional[list] = None):&#10;        self.item = item&#10;        self.quantity = quantity&#10;        self.source = source&#10;        self.target = target&#10;        self.status = status  # e.g., 'pending', 'in_transit', 'fulfilled', 'cancelled', 'blocked', 'queued'&#10;        self.created_at = created_at&#10;        self.updated_at = created_at&#10;        self.type = order_type  # 'production', 'transport', 'request', etc.&#10;        self.blocking_resources = blocking_resources if blocking_resources is not None else []&#10;&#10;    def update_status(self, new_status: str, timestamp: Optional[float] = None):&#10;        self.status = new_status&#10;        if timestamp:&#10;            self.updated_at = timestamp&#10;&#10;    def __repr__(self):&#10;        return f&quot;&lt;Order {self.item} x{self.quantity} {self.source.node_id}-&gt;{self.target.node_id} type={self.type} status={self.status} blocked={self.blocking_resources}&gt;&quot;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/services/inventory/production_nodes.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/services/inventory/production_nodes.py" />
              <option name="originalContent" value="from typing import Dict, List, Optional, Any, Protocol&#10;from services.FoxholeDataObjects.processes import ProductionType, FacilityType, ProcessType, PRODUCTION_PROCESS_MAP&#10;from enum import Enum&#10;from services.inventory.inventory_graph import InventoryNode, InventoryEdge&#10;&#10;class BaseType(Enum):&#10;    RESOURCE = &quot;Resource&quot;&#10;    REFINERY = &quot;CrudeOil&quot;&#10;    PRODUCTION = &quot;Production&quot;&#10;    CRATE_NODE = &quot;CrateNode&quot;&#10;    ITEM_NODE = &quot;ItemNode&quot;&#10;    FACILITY = &quot;Facility&quot;&#10;&#10;class BaseNode:&#10;    def __init__(self, node_id: str, location_name: str, unit_size: str = &quot;crate&quot;&#10;                 , base_type: BaseType = BaseType.ITEM_NODE):&#10;        self.node_id = node_id&#10;        self.location_name = location_name&#10;        self.unit_size = unit_size&#10;        self.base_type = base_type&#10;        self.inventory: Dict[str, int] = {}&#10;        self.delta: Dict[str, int] = {}&#10;        self.status: str = &quot;unknown&quot;&#10;        self.metadata: Dict[str, Any] = {}&#10;        self.edges: List[Any] = []  # List of InventoryEdge objects&#10;        self.status_table: Dict[str, Dict[str, int]] = {}&#10;&#10;    def add_edge(self, edge: 'InventoryEdge'):&#10;        self.edges.append(edge)&#10;&#10;    def compute_delta_from_orders(self):&#10;        &quot;&quot;&quot;&#10;        Compute delta based on orders from downstream nodes.&#10;        Aggregates orders from all connected edges.&#10;        &quot;&quot;&quot;&#10;        total_orders: Dict[str, int] = {}&#10;        for edge in self.edges:&#10;            if hasattr(edge, 'get_orders'):&#10;                for order in edge.get_orders():&#10;                    item = order.item&#10;                    quantity = order.quantity&#10;                    total_orders[item] = total_orders.get(item, 0) + quantity&#10;        self.delta = total_orders&#10;&#10;class ProductionProcessSupport(Protocol):&#10;    def get_production_processes(self) -&gt; List[str]:&#10;        ...&#10;    def supports_production_process(self, process_label: str) -&gt; bool:&#10;        ...&#10;&#10;class ProductionNode(BaseNode, ProductionProcessSupport):&#10;    SUPPORTED_PROCESSES: list[str] = []&#10;&#10;    def __init__(self, node_id: str, location_name: str, unit_size: str = &quot;crate&quot;, base_type: BaseType = BaseType.PRODUCTION,&#10;                 production_type: ProductionType | None = None, facility_type: FacilityType | None = None,&#10;                 process_type: ProcessType | None = None, process_label: str | None = None):&#10;        super().__init__(node_id, location_name, unit_size, base_type)&#10;        self.production_type = production_type&#10;        self.facility_type = facility_type&#10;        self.process_type = process_type&#10;        self.process_label = process_label&#10;        self.in_production: dict[str, dict[str, Any]] = {}  # item -&gt; status/quantity&#10;        self.set_production_processes()&#10;&#10;    def set_production_processes(self, processes: list[str] | None = None):&#10;        &quot;&quot;&quot;&#10;        Sets the production processes for this node. Can be overloaded in subclasses.&#10;        Call super().set_production_processes() to extend logic.&#10;        &quot;&quot;&quot;&#10;        self.processes = processes or []&#10;&#10;    def get_production_processes(self) -&gt; list[str]:&#10;        # Only return processes if set by concrete class&#10;        return getattr(self, &quot;processes&quot;, [])&#10;&#10;    def supports_production_process(self, process_label: str) -&gt; bool:&#10;        return process_label in self.get_production_processes()&#10;&#10;class QueueableProductionNode(ProductionNode):&#10;    QUEUE_EXPIRY_WARNING_SECONDS = 15 * 60  # 15 minutes before expiration&#10;&#10;    def __init__(self, node_id: str, location_name: str, unit_size: str = &quot;crate&quot;, base_type: BaseType = BaseType.PRODUCTION,&#10;                 production_type: ProductionType | None = None, facility_type: FacilityType | None = None,&#10;                 process_type: ProcessType | None = None, process_label: str | None = None):&#10;        super().__init__(node_id, location_name, unit_size, base_type, production_type, facility_type, process_type, process_label)&#10;        self.queue_expiration: dict[str, float] = {}  # player -&gt; expiration timestamp&#10;        self.production_queue: dict[str, list[dict[str, Any]]] = {}  # player -&gt; queue of items&#10;&#10;    def add_to_queue(self, player: str, order: Dict[str, Any]):&#10;        if player not in self.production_queue:&#10;            self.production_queue[player] = []&#10;        self.production_queue[player].append(order)&#10;&#10;    def set_queue_expiration(self, player: str, expiration: float):&#10;        self.queue_expiration[player] = expiration&#10;&#10;    def get_player_queue(self, player: str) -&gt; List[Dict[str, Any]]:&#10;        return self.production_queue.get(player, [])&#10;&#10;    def check_queue_expiry_warnings(self):&#10;        import time&#10;        now = time.time()&#10;        for player, expiration in self.queue_expiration.items():&#10;            time_left = expiration - now&#10;            if 0 &lt; time_left &lt; self.QUEUE_EXPIRY_WARNING_SECONDS:&#10;                self.notify_queue_expiry_warning(player, time_left)&#10;&#10;    def notify_queue_expiry_warning(self, player: str, time_left: float):&#10;        # Placeholder for notification logic to be implemented in presentation layer&#10;        # For now, just print (replace with event dispatch in future)&#10;        print(f&quot;[Queue Expiry Warning] Player '{player}' queue will expire in {int(time_left // 60)} minutes.&quot;)&#10;&#10;    def add_production_order(self, item: str, quantity: int, target_node: 'InventoryNode', required_resources: Optional[Dict[str, int]] = None):&#10;        &quot;&quot;&quot;&#10;        Create a production order and attach to the appropriate edge.&#10;        If resources are missing, mark as blocked and list missing resources.&#10;        &quot;&quot;&quot;&#10;        from services.inventory.order import Order&#10;        missing_resources = []&#10;        if required_resources:&#10;            for res, amt in required_resources.items():&#10;                if self.inventory.get(res, 0) &lt; amt:&#10;                    missing_resources.append(res)&#10;        status = &quot;blocked&quot; if missing_resources else &quot;queued&quot;&#10;        order = Order(item, quantity, self, target_node, status=status, order_type=&quot;production&quot;, blocking_resources=missing_resources)&#10;        # Attach order to edge&#10;        for edge in self.edges:&#10;            if edge.target == target_node:&#10;                edge.add_order(order)&#10;                break&#10;&#10;class RefineryNode(QueueableProductionNode):&#10;    pass&#10;&#10;class FactoryNode(QueueableProductionNode):&#10;    SUPPORTED_PROCESSES = [&#10;        &quot;Uniform::Factory&quot;,&#10;        &quot;SmallArms::Factory&quot;,&#10;        &quot;HeavyArms::Factory&quot;,&#10;        &quot;HeavyAmmo::Factory&quot;,&#10;        &quot;Utility::Factory&quot;,&#10;        &quot;Medical::Factory&quot;,&#10;        &quot;MaintenanceSupplies::Factory&quot;&#10;    ]&#10;    MAX_CRATES_PER_ORDER = 4&#10;    MAX_ACTIVE_PLAYERS = 6&#10;    ORDER_EXPIRATION_SECONDS = 60 * 60  # 60 minutes&#10;&#10;    def __init__(self, node_id: str, location_name: str, unit_size: str = &quot;crate&quot;, base_type: BaseType = BaseType.PRODUCTION,&#10;                 production_type: ProductionType | None = None, facility_type: FacilityType | None = None,&#10;                 process_type: ProcessType | None = None, process_label: str | None = None):&#10;        super().__init__(node_id, location_name, unit_size, base_type, production_type, facility_type, process_type, process_label)&#10;        self.set_production_processes(self.SUPPORTED_PROCESSES)&#10;&#10;    def add_production_order(self, item: str, quantity: int, target_node: InventoryNode, required_resources: Optional[Dict[str, int]] = None):&#10;        process_label = required_resources.get(&quot;process_label&quot;) if required_resources else None&#10;        if process_label and process_label not in self.SUPPORTED_PROCESSES:&#10;            raise ValueError(f&quot;Process '{process_label}' not supported by FactoryNode.&quot;)&#10;        num_crates = required_resources.get(&quot;num_crates&quot;, 1) if required_resources else 1&#10;        if num_crates &gt; self.MAX_CRATES_PER_ORDER:&#10;            raise ValueError(f&quot;Cannot produce more than {self.MAX_CRATES_PER_ORDER} crates per order.&quot;)&#10;        # Add order and set expiration&#10;        super().add_production_order(item, quantity, target_node, required_resources)&#10;&#10;    def expire_orders(self):&#10;        # Edge-based: expire orders by status/timestamp if needed&#10;        import time&#10;        now = time.time()&#10;        expired_orders = []&#10;        for edge in self.edges:&#10;            for order in edge.get_orders():&#10;                if hasattr(order, 'created_at') and order.status == &quot;queued&quot;:&#10;                    if order.created_at and now - order.created_at &gt; self.ORDER_EXPIRATION_SECONDS:&#10;                        order.update_status(&quot;expired&quot;, now)&#10;                        expired_orders.append(order)&#10;        return expired_orders&#10;&#10;    def get_active_players(self) -&gt; List[str]:&#10;        # Edge-based: return unique sources of active orders&#10;        active_players = set()&#10;        for edge in self.edges:&#10;            for order in edge.get_orders():&#10;                if order.status in [&quot;queued&quot;, &quot;blocked&quot;]:&#10;                    active_players.add(order.source.node_id)&#10;        return list(active_players)&#10;&#10;class MassProductionFactoryNode(QueueableProductionNode):&#10;    SUPPORTED_PROCESSES = [&#10;        &quot;SmallArms::MPF&quot;,&#10;        &quot;HeavyArms::MPF&quot;,&#10;        &quot;HeavyAmmo::MPF&quot;,&#10;        &quot;MaintenanceSupplies::MPF&quot;,&#10;        &quot;Uniform::MPF&quot;,&#10;        &quot;Vehicle::MPF&quot;,&#10;        &quot;Ship::MPF&quot;,&#10;        &quot;Shippable::MPF&quot;&#10;    ]&#10;    MPF_CRATE_DISCOUNTS = [0.10, 0.15, 0.20, 0.25, 0.30, 0.333333, 0.357143, 0.375, 0.388889]&#10;&#10;    def __init__(self, node_id: str, location_name: str, unit_size: str = &quot;crate&quot;, base_type: BaseType = BaseType.PRODUCTION,&#10;                 production_type: ProductionType | None = None, facility_type: FacilityType | None = None,&#10;                 process_type: ProcessType | None = None, process_label: str | None = None):&#10;        super().__init__(node_id, location_name, unit_size, base_type, production_type, facility_type, process_type, process_label)&#10;        self.set_production_processes(self.SUPPORTED_PROCESSES)&#10;&#10;    def add_production_order(self, item: str, quantity: int, target_node: InventoryNode, required_resources: Optional[Dict[str, int]] = None):&#10;        process_label = required_resources.get(&quot;process_label&quot;) if required_resources else None&#10;        if process_label not in self.SUPPORTED_PROCESSES:&#10;            raise ValueError(f&quot;Process '{process_label}' not supported by MassProductionFactoryNode.&quot;)&#10;        # Shared queue for Vehicle::MPF and Ship::MPF is now edge-based&#10;        super().add_production_order(item, quantity, target_node, required_resources)&#10;&#10;    def get_player_queue(self, player: str) -&gt; List[Dict[str, Any]]:&#10;        # For shared vehicle/ship queue, return that if requested&#10;        if player == &quot;mpf_vehicle&quot;:&#10;            return self.production_queue.get(&quot;mpf_vehicle&quot;, [])&#10;        return super().get_player_queue(player)&#10;&#10;    @staticmethod&#10;    def get_crate_discount_percentage(self, num_crates: int) -&gt; float:&#10;        &quot;&quot;&quot;&#10;        Returns the cached discount percentage for the given number of crates (1-9).&#10;        If num_crates is out of range, returns the closest available value.&#10;        &quot;&quot;&quot;&#10;        idx = max(0, min(num_crates - 1, len(self.MPF_CRATE_DISCOUNTS) - 1))&#10;        return self.MPF_CRATE_DISCOUNTS[idx]&#10;&#10;    @staticmethod&#10;    def calculate_crate_cost(self, num_crates: int, base_resource_amount: float) -&gt; float:&#10;        &quot;&quot;&quot;&#10;        Returns the total cost using the cached discount percentage for the given number of crates.&#10;        Multiplies the base resource amount by (1 - discount).&#10;&#10;        This uses a lookup table with the discounts prepopulated.&#10;        &quot;&quot;&quot;&#10;        discount = self.get_crate_discount_percentage(num_crates)&#10;        return base_resource_amount * (1 - discount)&#10;&#10;    @staticmethod&#10;    def calculate_crate_cost_slow(num_crates: int, base_cost: float, item_type: str) -&gt; float:&#10;        &quot;&quot;&quot;&#10;        Returns the total cost after MPF discount for the given number of crates.&#10;        Vehicles and shippables: max 5 crates (max 50% discount, average 30% across whole queue).&#10;        All other categories: max 9 crates (max 50% discount, average 38.8889% across whole queue).&#10;        &quot;&quot;&quot;&#10;        if item_type in [&quot;vehicle&quot;, &quot;shippable&quot;]:&#10;            max_crates = 5&#10;        else:&#10;            max_crates = 9&#10;        discount_crates = min(num_crates, max_crates)&#10;        discount = 0.1 * discount_crates  # 10% per crate up to max&#10;        effective_cost = base_cost * (1 - discount)&#10;        return effective_cost&#10;&#10;    @staticmethod&#10;    def calculate_production_time(self, num_orders: int, item_type: str) -&gt; float:&#10;        &quot;&quot;&quot;&#10;        Returns the effective production time per order based on queue size and item type.&#10;        For item crates: max speedup is 15x&#10;        For vehicle/shippable crates: max speedup is 12x&#10;        Uses straight-line slopes to calculate time based on number of orders.&#10;        &quot;&quot;&quot;&#10;        if not 1 &lt;= num_orders &lt;= 25:&#10;            raise ValueError(f&quot;Input value {num_orders} is not within the 1-25 range for the MPF.&quot;)&#10;&#10;        if item_type in [&quot;vehicle&quot;, &quot;shippable&quot;]:&#10;            return 0.4791666667 * num_orders + 0.5208333333&#10;        else:&#10;            return 0.5833333333 * num_orders + 0.4166666667&#10;&#10;&#10;    def get_density_info(self, item_type: str) -&gt; dict:&#10;        &quot;&quot;&quot;&#10;        Returns density info for the item type.&#10;        For vehicles/shippables, output is a ShippableCrate with 3 items, only unpackable at LogiStorage.&#10;        For item crates, standard crate size applies.&#10;        &quot;&quot;&quot;&#10;        if item_type in [&quot;vehicle&quot;, &quot;structure&quot;, &quot;shippable&quot;]:&#10;            return {&#10;                &quot;crate_type&quot;: &quot;ShippableCrate&quot;,&#10;                &quot;items_per_crate&quot;: 3,&#10;                &quot;unpack_location&quot;: &quot;LogiStorage&quot;&#10;            }&#10;        else:&#10;            return {&#10;                &quot;crate_type&quot;: &quot;StandardCrate&quot;,&#10;                &quot;items_per_crate&quot;: 1,&#10;                &quot;unpack_location&quot;: &quot;Any&quot;&#10;            }&#10;&#10;&#10;class CharacterProductionNode(ProductionNode):&#10;    def __init__(self, node_id: str, location_name: str, unit_size: str = &quot;crate&quot;, base_type: BaseType = BaseType.PRODUCTION,&#10;                 production_type: ProductionType | None = None, facility_type: FacilityType | None = None,&#10;                 process_type: ProcessType | None = None, process_label: str | None = None,&#10;                 supported_processes: list[str] | None = None):&#10;        super().__init__(node_id, location_name, unit_size, base_type, production_type, facility_type, process_type, process_label)&#10;        self.instant_build: bool = True  # disables queue logic&#10;        if supported_processes:&#10;            self.set_production_processes(supported_processes)&#10;&#10;    def build_item(self, item: str, quantity: int):&#10;        # Simulate instant build&#10;        self.inventory[item] = self.inventory.get(item, 0) + quantity&#10;" />
              <option name="updatedContent" value="from typing import Dict, List, Optional, Any, Protocol&#10;from services.FoxholeDataObjects.processes import ProductionType, FacilityType, ProcessType, PRODUCTION_PROCESS_MAP&#10;from enum import Enum&#10;from services.inventory.inventory_graph import InventoryNode, InventoryEdge&#10;&#10;class BaseType(Enum):&#10;    RESOURCE = &quot;Resource&quot;&#10;    REFINERY = &quot;CrudeOil&quot;&#10;    PRODUCTION = &quot;Production&quot;&#10;    CRATE_NODE = &quot;CrateNode&quot;&#10;    ITEM_NODE = &quot;ItemNode&quot;&#10;    FACILITY = &quot;Facility&quot;&#10;&#10;class BaseNode:&#10;    def __init__(self, node_id: str, location_name: str, unit_size: str = &quot;crate&quot;&#10;                 , base_type: BaseType = BaseType.ITEM_NODE):&#10;        self.node_id = node_id&#10;        self.location_name = location_name&#10;        self.unit_size = unit_size&#10;        self.base_type = base_type&#10;        self.inventory: Dict[str, int] = {}&#10;        self.delta: Dict[str, int] = {}&#10;        self.status: str = &quot;unknown&quot;&#10;        self.metadata: Dict[str, Any] = {}&#10;        self.edges: List[Any] = []  # List of InventoryEdge objects&#10;        self.status_table: Dict[str, Dict[str, int]] = {}&#10;&#10;    def add_edge(self, edge: 'InventoryEdge'):&#10;        self.edges.append(edge)&#10;&#10;    def compute_delta_from_orders(self):&#10;        &quot;&quot;&quot;&#10;        Compute delta based on orders from downstream nodes.&#10;        Aggregates orders from all connected edges.&#10;        &quot;&quot;&quot;&#10;        total_orders: Dict[str, int] = {}&#10;        for edge in self.edges:&#10;            if hasattr(edge, 'get_orders'):&#10;                for order in edge.get_orders():&#10;                    item = order.item&#10;                    quantity = order.quantity&#10;                    total_orders[item] = total_orders.get(item, 0) + quantity&#10;        self.delta = total_orders&#10;&#10;class ProductionProcessSupport(Protocol):&#10;    def get_production_processes(self) -&gt; List[str]:&#10;        ...&#10;    def supports_production_process(self, process_label: str) -&gt; bool:&#10;        ...&#10;&#10;class ProductionNode(BaseNode, ProductionProcessSupport):&#10;    SUPPORTED_PROCESSES: list[str] = []&#10;&#10;    def __init__(self, node_id: str, location_name: str, unit_size: str = &quot;crate&quot;, base_type: BaseType = BaseType.PRODUCTION,&#10;                 production_type: ProductionType | None = None, facility_type: FacilityType | None = None,&#10;                 process_type: ProcessType | None = None, process_label: str | None = None):&#10;        super().__init__(node_id, location_name, unit_size, base_type)&#10;        self.production_type = production_type&#10;        self.facility_type = facility_type&#10;        self.process_type = process_type&#10;        self.process_label = process_label&#10;        self.in_production: dict[str, dict[str, Any]] = {}  # item -&gt; status/quantity&#10;        self.set_production_processes()&#10;&#10;    def set_production_processes(self, processes: list[str] | None = None):&#10;        &quot;&quot;&quot;&#10;        Sets the production processes for this node. Can be overloaded in subclasses.&#10;        Call super().set_production_processes() to extend logic.&#10;        &quot;&quot;&quot;&#10;        self.processes = processes or []&#10;&#10;    def get_production_processes(self) -&gt; list[str]:&#10;        # Only return processes if set by concrete class&#10;        return getattr(self, &quot;processes&quot;, [])&#10;&#10;    def supports_production_process(self, process_label: str) -&gt; bool:&#10;        return process_label in self.get_production_processes()&#10;&#10;class QueueableProductionNode(ProductionNode):&#10;    QUEUE_EXPIRY_WARNING_SECONDS = 15 * 60  # 15 minutes before expiration&#10;&#10;    def __init__(self, node_id: str, location_name: str, unit_size: str = &quot;crate&quot;, base_type: BaseType = BaseType.PRODUCTION,&#10;                 production_type: ProductionType | None = None, facility_type: FacilityType | None = None,&#10;                 process_type: ProcessType | None = None, process_label: str | None = None):&#10;        super().__init__(node_id, location_name, unit_size, base_type, production_type, facility_type, process_type, process_label)&#10;        self.queue_expiration: dict[str, float] = {}  # player -&gt; expiration timestamp&#10;        self.production_queue: dict[str, list[dict[str, Any]]] = {}  # player -&gt; queue of items&#10;&#10;    def add_to_queue(self, player: str, order: Dict[str, Any]):&#10;        if player not in self.production_queue:&#10;            self.production_queue[player] = []&#10;        self.production_queue[player].append(order)&#10;&#10;    def set_queue_expiration(self, player: str, expiration: float):&#10;        self.queue_expiration[player] = expiration&#10;&#10;    def get_player_queue(self, player: str) -&gt; List[Dict[str, Any]]:&#10;        return self.production_queue.get(player, [])&#10;&#10;    def check_queue_expiry_warnings(self):&#10;        import time&#10;        now = time.time()&#10;        for player, expiration in self.queue_expiration.items():&#10;            time_left = expiration - now&#10;            if 0 &lt; time_left &lt; self.QUEUE_EXPIRY_WARNING_SECONDS:&#10;                self.notify_queue_expiry_warning(player, time_left)&#10;&#10;    def notify_queue_expiry_warning(self, player: str, time_left: float):&#10;        # Placeholder for notification logic to be implemented in presentation layer&#10;        # For now, just print (replace with event dispatch in future)&#10;        print(f&quot;[Queue Expiry Warning] Player '{player}' queue will expire in {int(time_left // 60)} minutes.&quot;)&#10;&#10;    def add_production_order(self, item: str, quantity: int, target_node: 'InventoryNode', required_resources: Optional[Dict[str, int]] = None):&#10;        &quot;&quot;&quot;&#10;        Create a production order and attach to the appropriate edge.&#10;        If resources are missing, mark as blocked and list missing resources.&#10;        &quot;&quot;&quot;&#10;        from services.inventory.order import Order&#10;        missing_resources = []&#10;        if required_resources:&#10;            for res, amt in required_resources.items():&#10;                if self.inventory.get(res, 0) &lt; amt:&#10;                    missing_resources.append(res)&#10;        status = &quot;blocked&quot; if missing_resources else &quot;queued&quot;&#10;        order = Order(item, quantity, self, target_node, status=status, order_type=&quot;production&quot;, blocking_resources=missing_resources)&#10;        # Attach order to edge&#10;        for edge in self.edges:&#10;            if edge.target == target_node:&#10;                edge.add_order(order)&#10;                break&#10;&#10;class RefineryNode(QueueableProductionNode):&#10;    pass&#10;&#10;class FactoryNode(QueueableProductionNode):&#10;    SUPPORTED_PROCESSES = [&#10;        &quot;Uniform::Factory&quot;,&#10;        &quot;SmallArms::Factory&quot;,&#10;        &quot;HeavyArms::Factory&quot;,&#10;        &quot;HeavyAmmo::Factory&quot;,&#10;        &quot;Utility::Factory&quot;,&#10;        &quot;Medical::Factory&quot;,&#10;        &quot;MaintenanceSupplies::Factory&quot;&#10;    ]&#10;    MAX_CRATES_PER_ORDER = 4&#10;    MAX_ACTIVE_PLAYERS = 6&#10;    ORDER_EXPIRATION_SECONDS = 60 * 60  # 60 minutes&#10;&#10;    def __init__(self, node_id: str, location_name: str, unit_size: str = &quot;crate&quot;, base_type: BaseType = BaseType.PRODUCTION,&#10;                 production_type: ProductionType | None = None, facility_type: FacilityType | None = None,&#10;                 process_type: ProcessType | None = None, process_label: str | None = None):&#10;        super().__init__(node_id, location_name, unit_size, base_type, production_type, facility_type, process_type, process_label)&#10;        self.set_production_processes(self.SUPPORTED_PROCESSES)&#10;&#10;    def add_production_order(self, item: str, quantity: int, target_node: InventoryNode, required_resources: Optional[Dict[str, int]] = None):&#10;        process_label = required_resources.get(&quot;process_label&quot;) if required_resources else None&#10;        if process_label and process_label not in self.SUPPORTED_PROCESSES:&#10;            raise ValueError(f&quot;Process '{process_label}' not supported by FactoryNode.&quot;)&#10;        num_crates = required_resources.get(&quot;num_crates&quot;, 1) if required_resources else 1&#10;        if num_crates &gt; self.MAX_CRATES_PER_ORDER:&#10;            raise ValueError(f&quot;Cannot produce more than {self.MAX_CRATES_PER_ORDER} crates per order.&quot;)&#10;        # Add order and set expiration&#10;        super().add_production_order(item, quantity, target_node, required_resources)&#10;&#10;    def expire_orders(self):&#10;        # Edge-based: expire orders by status/timestamp if needed&#10;        import time&#10;        now = time.time()&#10;        expired_orders = []&#10;        for edge in self.edges:&#10;            for order in edge.get_orders():&#10;                if hasattr(order, 'created_at') and order.status == &quot;queued&quot;:&#10;                    if order.created_at and now - order.created_at &gt; self.ORDER_EXPIRATION_SECONDS:&#10;                        order.update_status(&quot;expired&quot;, now)&#10;                        expired_orders.append(order)&#10;        return expired_orders&#10;&#10;    def get_active_players(self) -&gt; List[str]:&#10;        # Edge-based: return unique sources of active orders&#10;        active_players = set()&#10;        for edge in self.edges:&#10;            for order in edge.get_orders():&#10;                if order.status in [&quot;queued&quot;, &quot;blocked&quot;]:&#10;                    active_players.add(order.source.node_id)&#10;        return list(active_players)&#10;&#10;class MassProductionFactoryNode(QueueableProductionNode):&#10;    SUPPORTED_PROCESSES = [&#10;        &quot;SmallArms::MPF&quot;,&#10;        &quot;HeavyArms::MPF&quot;,&#10;        &quot;HeavyAmmo::MPF&quot;,&#10;        &quot;MaintenanceSupplies::MPF&quot;,&#10;        &quot;Uniform::MPF&quot;,&#10;        &quot;Vehicle::MPF&quot;,&#10;        &quot;Ship::MPF&quot;,&#10;        &quot;Shippable::MPF&quot;&#10;    ]&#10;    MPF_CRATE_DISCOUNTS = [0.10, 0.15, 0.20, 0.25, 0.30, 0.333333, 0.357143, 0.375, 0.388889]&#10;&#10;    def __init__(self, node_id: str, location_name: str, unit_size: str = &quot;crate&quot;, base_type: BaseType = BaseType.PRODUCTION,&#10;                 production_type: ProductionType | None = None, facility_type: FacilityType | None = None,&#10;                 process_type: ProcessType | None = None, process_label: str | None = None):&#10;        super().__init__(node_id, location_name, unit_size, base_type, production_type, facility_type, process_type, process_label)&#10;        self.set_production_processes(self.SUPPORTED_PROCESSES)&#10;&#10;    def add_production_order(self, item: str, quantity: int, target_node: InventoryNode, required_resources: Optional[Dict[str, int]] = None):&#10;        process_label = required_resources.get(&quot;process_label&quot;) if required_resources else None&#10;        if process_label not in self.SUPPORTED_PROCESSES:&#10;            raise ValueError(f&quot;Process '{process_label}' not supported by MassProductionFactoryNode.&quot;)&#10;        # Shared queue for Vehicle::MPF and Ship::MPF is now edge-based&#10;        super().add_production_order(item, quantity, target_node, required_resources)&#10;&#10;    @staticmethod&#10;    def get_crate_discount_percentage(self, num_crates: int) -&gt; float:&#10;        &quot;&quot;&quot;&#10;        Returns the cached discount percentage for the given number of crates (1-9).&#10;        If num_crates is out of range, returns the closest available value.&#10;        &quot;&quot;&quot;&#10;        idx = max(0, min(num_crates - 1, len(self.MPF_CRATE_DISCOUNTS) - 1))&#10;        return self.MPF_CRATE_DISCOUNTS[idx]&#10;&#10;    @staticmethod&#10;    def calculate_crate_cost(self, num_crates: int, base_resource_amount: float) -&gt; float:&#10;        &quot;&quot;&quot;&#10;        Returns the total cost using the cached discount percentage for the given number of crates.&#10;        Multiplies the base resource amount by (1 - discount).&#10;&#10;        This uses a lookup table with the discounts prepopulated.&#10;        &quot;&quot;&quot;&#10;        discount = self.get_crate_discount_percentage(num_crates)&#10;        return base_resource_amount * (1 - discount)&#10;&#10;    @staticmethod&#10;    def calculate_crate_cost_slow(num_crates: int, base_cost: float, item_type: str) -&gt; float:&#10;        &quot;&quot;&quot;&#10;        Returns the total cost after MPF discount for the given number of crates.&#10;        Vehicles and shippables: max 5 crates (max 50% discount, average 30% across whole queue).&#10;        All other categories: max 9 crates (max 50% discount, average 38.8889% across whole queue).&#10;        &quot;&quot;&quot;&#10;        if item_type in [&quot;vehicle&quot;, &quot;shippable&quot;]:&#10;            max_crates = 5&#10;        else:&#10;            max_crates = 9&#10;        discount_crates = min(num_crates, max_crates)&#10;        discount = 0.1 * discount_crates  # 10% per crate up to max&#10;        effective_cost = base_cost * (1 - discount)&#10;        return effective_cost&#10;&#10;    @staticmethod&#10;    def calculate_production_time(self, num_orders: int, item_type: str) -&gt; float:&#10;        &quot;&quot;&quot;&#10;        Returns the effective production time per order based on queue size and item type.&#10;        For item crates: max speedup is 15x&#10;        For vehicle/shippable crates: max speedup is 12x&#10;        Uses straight-line slopes to calculate time based on number of orders.&#10;        &quot;&quot;&quot;&#10;        if not 1 &lt;= num_orders &lt;= 25:&#10;            raise ValueError(f&quot;Input value {num_orders} is not within the 1-25 range for the MPF.&quot;)&#10;&#10;        if item_type in [&quot;vehicle&quot;, &quot;shippable&quot;]:&#10;            return 0.4791666667 * num_orders + 0.5208333333&#10;        else:&#10;            return 0.5833333333 * num_orders + 0.4166666667&#10;&#10;&#10;    def get_density_info(self, item_type: str) -&gt; dict:&#10;        &quot;&quot;&quot;&#10;        Returns density info for the item type.&#10;        For vehicles/shippables, output is a ShippableCrate with 3 items, only unpackable at LogiStorage.&#10;        For item crates, standard crate size applies.&#10;        &quot;&quot;&quot;&#10;        if item_type in [&quot;vehicle&quot;, &quot;structure&quot;, &quot;shippable&quot;]:&#10;            return {&#10;                &quot;crate_type&quot;: &quot;ShippableCrate&quot;,&#10;                &quot;items_per_crate&quot;: 3,&#10;                &quot;unpack_location&quot;: &quot;LogiStorage&quot;&#10;            }&#10;        else:&#10;            return {&#10;                &quot;crate_type&quot;: &quot;StandardCrate&quot;,&#10;                &quot;items_per_crate&quot;: 1,&#10;                &quot;unpack_location&quot;: &quot;Any&quot;&#10;            }&#10;&#10;&#10;class CharacterProductionNode(ProductionNode):&#10;    def __init__(self, node_id: str, location_name: str, unit_size: str = &quot;crate&quot;, base_type: BaseType = BaseType.PRODUCTION,&#10;                 production_type: ProductionType | None = None, facility_type: FacilityType | None = None,&#10;                 process_type: ProcessType | None = None, process_label: str | None = None,&#10;                 supported_processes: list[str] | None = None):&#10;        super().__init__(node_id, location_name, unit_size, base_type, production_type, facility_type, process_type, process_label)&#10;        self.instant_build: bool = True  # disables queue logic&#10;        if supported_processes:&#10;            self.set_production_processes(supported_processes)&#10;&#10;    def build_item(self, item: str, quantity: int):&#10;        # Simulate instant build&#10;        self.inventory[item] = self.inventory.get(item, 0) + quantity" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/tests/data/discord/test_retry_env.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/tests/data/discord/test_retry_env.py" />
              <option name="originalContent" value="import asyncio&#10;&#10;# Assume DiscordBot is imported from the correct location&#10;    # Ensure an event loop exists for tests that need it&#10;        loop = asyncio.new_event_loop()&#10;    # Clean up the event loop after each test&#10;    try:&#10;        asyncio.get_event_loop()&#10;        loop.close()&#10;    except RuntimeError:&#10;        pass&#10;&#10;def test_env_defaults(monkeypatch):&#10;    # Remove env vars if set&#10;    monkeypatch.delenv('DISCORD_BOT_MAX_RETRIES', raising=False)&#10;    monkeypatch.delenv('DISCORD_BOT_RETRY_DELAY', raising=False)&#10;    # Access the retry config (simulate how your code reads it)&#10;    max_retries = int(os.environ.get('DISCORD_BOT_MAX_RETRIES', 3))&#10;    retry_delay = int(os.environ.get('DISCORD_BOT_RETRY_DELAY', 15))&#10;    assert max_retries == 3&#10;    assert retry_delay == 15&#10;&#10;def test_env_override(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '5')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '42')&#10;    max_retries = int(os.environ.get('DISCORD_BOT_MAX_RETRIES', 3))&#10;    retry_delay = int(os.environ.get('DISCORD_BOT_RETRY_DELAY', 15))&#10;    assert max_retries == 5&#10;    assert retry_delay == 42&#10;&#10;def test_retry_on_exception(monkeypatch):&#10;    # Set retries to 2 for a quick test&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '2')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '0')  # No sleep delay&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()  # Mock logger to avoid real logging&#10;    # Mock client.run to always raise Exception&#10;    bot.client.run = mock.Mock(side_effect=Exception('fail'))&#10;    with pytest.raises(Exception):&#10;        bot.run()&#10;    # Should attempt to run 1 initial + 2 retries = 3 times&#10;    assert bot.client.run.call_count == 3&#10;    # Check that error and retry logs were called&#10;    assert bot.logger.error.call_count &gt;= 3&#10;    assert any('Attempting to reconnect' in str(call) for call in bot.logger.info.call_args_list)&#10;&#10;def test_login_failure(monkeypatch):&#10;    from disnake import LoginFailure&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    # Mock client.run to raise LoginFailure&#10;    bot.client.run = mock.Mock(side_effect=LoginFailure('bad token'))&#10;    with pytest.raises(LoginFailure):&#10;        bot.run()&#10;    # Should only try once&#10;    assert bot.client.run.call_count == 1&#10;    assert any('Authentication failed' in str(call) for call in bot.logger.error.call_args_list)&#10;&#10;def test_no_retries(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '0')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '0')&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.run = mock.Mock(side_effect=Exception('fail'))&#10;    with pytest.raises(Exception):&#10;        bot.run()&#10;    # Should only try once (no retries)&#10;    assert bot.client.run.call_count == 1&#10;    assert bot.logger.error.call_count &gt;= 1&#10;&#10;def test_negative_retries(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '-1')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '0')&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.run = mock.Mock(side_effect=Exception('fail'))&#10;    with pytest.raises(Exception):&#10;        bot.run()&#10;    # Class should only try once. Negative retries are treated as 0.&#10;    assert bot.client.run.call_count == 1&#10;    assert bot.logger.error.call_count &gt;= 1&#10;&#10;def test_non_integer_retries(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', 'abc')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '0')&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.run = mock.Mock(side_effect=Exception('fail'))&#10;    with pytest.raises(ValueError):&#10;        bot.run()&#10;&#10;def test_non_integer_delay(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '1')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', 'xyz')&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.run = mock.Mock(side_effect=Exception('fail'))&#10;    with pytest.raises(ValueError):&#10;        bot.run()&#10;&#10;def test_zero_retry_delay(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '2')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '0')&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.run = mock.Mock(side_effect=Exception('fail'))&#10;    # Patch sleep to track calls&#10;    with mock.patch('time.sleep') as mock_sleep:&#10;        with pytest.raises(Exception):&#10;            bot.run()&#10;        # Should attempt to run 1 initial + 2 retries = 3 times&#10;        assert bot.client.run.call_count == 3&#10;        # sleep should not be called since delay is 0&#10;        mock_sleep.assert_not_called()&#10;&#10;def test_retry_succeeds(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '2')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '0')&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    # First call fails, second call succeeds&#10;    bot.client.run = mock.Mock(side_effect=[Exception('fail'), None])&#10;    # Should not raise, since the second attempt succeeds&#10;    bot.run()&#10;    assert bot.client.run.call_count == 2&#10;    # Should log error for first failure, but not raise&#10;    assert bot.logger.error.call_count &gt;= 1&#10;&#10;def test_shutdown_exception(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.is_closed = mock.Mock(return_value=False)&#10;    bot.client.close = mock.Mock(side_effect=Exception('shutdown fail'))&#10;    # Patch asyncio to avoid real event loop usage&#10;    with mock.patch('asyncio.get_running_loop', side_effect=RuntimeError()):&#10;        with mock.patch('asyncio.new_event_loop') as mock_new_loop:&#10;            mock_loop = mock.Mock()&#10;            mock_new_loop.return_value = mock_loop&#10;            mock_loop.is_running.return_value = False&#10;            bot.shutdown(loop=mock_loop)&#10;    # Should log the shutdown error&#10;    assert any('shutdown fail' in str(call) for call in bot.logger.error.call_args_list)&#10;&#10;def test_on_ready_sets_connected_and_logs(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    # Simulate event&#10;    asyncio.run(bot.on_ready())&#10;    assert bot.connected is True&#10;    assert any('Connected to Discord as' in str(call) for call in bot.logger.info.call_args_list)&#10;&#10;def test_on_disconnect_sets_disconnected_and_logs(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.connected = True&#10;    asyncio.run(bot.on_disconnect())&#10;    assert bot.connected is False&#10;    assert any('Disconnected from Discord' in str(call) for call in bot.logger.warning.call_args_list)&#10;&#10;def test_on_resumed_sets_connected_and_logs(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.connected = False&#10;    asyncio.run(bot.on_resumed())&#10;    assert bot.connected is True&#10;    assert any('Reconnected to Discord.' in str(call) for call in bot.logger.info.call_args_list)&#10;&#10;class DummyUser:&#10;    def __str__(self):&#10;        return &quot;TestUser&quot;&#10;&#10;def test_on_ready_with_user(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    # Patch client with a mock that has a user property&#10;    class ClientWithUser:&#10;        user = 'TestUser'&#10;    bot.client = ClientWithUser()&#10;    asyncio.run(bot.on_ready())&#10;    assert bot.connected is True&#10;    assert any('Connected to Discord as TestUser' in str(call) for call in bot.logger.info.call_args_list)&#10;&#10;def test_on_disconnect_with_user(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    class ClientWithUser:&#10;        user = 'TestUser'&#10;    bot.client = ClientWithUser()&#10;    bot.connected = True&#10;    asyncio.run(bot.on_disconnect())&#10;    assert bot.connected is False&#10;    assert any('Disconnected from Discord' in str(call) for call in bot.logger.warning.call_args_list)&#10;&#10;def test_on_resumed_with_user(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    class ClientWithUser:&#10;        user = 'TestUser'&#10;    bot.client = ClientWithUser()&#10;    bot.connected = False&#10;    asyncio.run(bot.on_resumed())&#10;    assert bot.connected is True&#10;    assert any('Reconnected to Discord.' in str(call) for call in bot.logger.info.call_args_list)&#10;&#10;def test_run_login_failure_non_mock(monkeypatch):&#10;    from disnake import LoginFailure&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    # Patch client to not be a mock&#10;    class DummyClient:&#10;        def run(self, token):&#10;            raise LoginFailure('bad token')&#10;    bot.client = DummyClient()&#10;    with pytest.raises(LoginFailure):&#10;        bot.run()&#10;    assert any('Authentication failed' in str(call) for call in bot.logger.error.call_args_list)&#10;&#10;def test_shutdown_running_loop_add_done_callback(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.is_closed = mock.Mock(return_value=False)&#10;    async def fake_close():&#10;        # This is a fake coroutine to simulate close&#10;        pass&#10;    coro = fake_close()&#10;    bot.client.close = mock.Mock(return_value=coro)&#10;    # Patch asyncio to avoid real event loop usage&#10;    with mock.patch('asyncio.get_running_loop', side_effect=RuntimeError()):&#10;        with mock.patch('asyncio.new_event_loop') as mock_new_loop:&#10;            mock_loop = mock.Mock()&#10;            mock_new_loop.return_value = mock_loop&#10;            mock_loop.is_running.return_value = True&#10;            # Simulate create_task and add_done_callback&#10;            class DummyTask:&#10;                def add_done_callback(self, cb):&#10;                    cb(self)&#10;            mock_loop.create_task = mock.Mock(return_value=DummyTask())&#10;            bot.shutdown(loop=mock_loop)&#10;    assert any('Bot disconnected gracefully.' in str(call) for call in bot.logger.info.call_args_list)&#10;    coro.close()&#10;&#10;def test_shutdown_returns_if_client_closed(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.is_closed = mock.Mock(return_value=True)&#10;    # Should return early, not call close&#10;    bot.client.close = mock.Mock()&#10;    bot.shutdown()&#10;    bot.client.close.assert_not_called()&#10;&#10;def test_shutdown_returns_if_client_is_mock(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client = mock.Mock()&#10;    bot.client.is_closed.return_value = False&#10;    # Should return early if the client is a mock&#10;    bot.shutdown()&#10;    # Should not call close or log warning&#10;    assert not bot.logger.warning.called&#10;&#10;def test_shutdown_logs_warning_if_close_not_awaitable(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.is_closed = mock.Mock(return_value=False)&#10;    # close returns a non-awaitable&#10;    bot.client.close = mock.Mock(return_value=None)&#10;    # Patch asyncio to avoid real event loop usage&#10;    with mock.patch('asyncio.get_running_loop', side_effect=RuntimeError()):&#10;        with mock.patch('asyncio.new_event_loop') as mock_new_loop:&#10;            mock_loop = mock.Mock()&#10;            mock_new_loop.return_value = mock_loop&#10;            mock_loop.is_running.return_value = False&#10;            bot.shutdown(loop=mock_loop)&#10;    assert any('did not return a coroutine' in str(call) for call in bot.logger.warning.call_args_list)&#10;&#10;def test_shutdown_logs_graceful_disconnect(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.is_closed = mock.Mock(return_value=False)&#10;    async def fake_close():&#10;        # This is a fake coroutine to simulate close&#10;        pass&#10;    coro = fake_close()&#10;    bot.client.close = mock.Mock(return_value=coro)&#10;    # Patch asyncio to avoid real event loop usage&#10;    with mock.patch('asyncio.get_running_loop', side_effect=RuntimeError()):&#10;        with mock.patch('asyncio.new_event_loop') as mock_new_loop:&#10;            mock_loop = mock.Mock()&#10;            mock_new_loop.return_value = mock_loop&#10;            mock_loop.is_running.return_value = False&#10;            # Simulate run_until_complete&#10;            def run_until_complete():&#10;                return None&#10;            mock_loop.run_until_complete = run_until_complete&#10;            bot.shutdown(loop=mock_loop)&#10;    assert any('Bot disconnected gracefully.' in str(call) for call in bot.logger.info.call_args_list)&#10;    coro.close()&#10;&#10;def test_is_connected():&#10;    bot = DiscordBot(token='dummy')&#10;    bot.connected = True&#10;    assert bot.is_connected() is True&#10;    bot.connected = False&#10;    assert bot.is_connected() is False&#10;" />
              <option name="updatedContent" value="import sys&#10;import os&#10;import pytest&#10;from unittest import mock&#10;import asyncio&#10;&#10;# Add the project root to sys.path so 'data' can be imported&#10;sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../..')))&#10;&#10;# Assume DiscordBot is imported from the correct location&#10;from data.discord.discord import DiscordBot&#10;&#10;def setup_function():&#10;    # Ensure an event loop exists for tests that need it&#10;    try:&#10;        asyncio.get_running_loop()&#10;    except RuntimeError:&#10;        loop = asyncio.new_event_loop()&#10;        asyncio.set_event_loop(loop)&#10;&#10;def teardown_function():&#10;    # Clean up the event loop after each test&#10;    try:&#10;        loop = asyncio.get_event_loop()&#10;        loop.close()&#10;    except RuntimeError:&#10;        pass&#10;&#10;def test_env_defaults(monkeypatch):&#10;    # Remove env vars if set&#10;    monkeypatch.delenv('DISCORD_BOT_MAX_RETRIES', raising=False)&#10;    monkeypatch.delenv('DISCORD_BOT_RETRY_DELAY', raising=False)&#10;    # Access the retry config (simulate how your code reads it)&#10;    max_retries = int(os.environ.get('DISCORD_BOT_MAX_RETRIES', 3))&#10;    retry_delay = int(os.environ.get('DISCORD_BOT_RETRY_DELAY', 15))&#10;    assert max_retries == 3&#10;    assert retry_delay == 15&#10;&#10;def test_env_override(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '5')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '42')&#10;    max_retries = int(os.environ.get('DISCORD_BOT_MAX_RETRIES', 3))&#10;    retry_delay = int(os.environ.get('DISCORD_BOT_RETRY_DELAY', 15))&#10;    assert max_retries == 5&#10;    assert retry_delay == 42&#10;&#10;def test_retry_on_exception(monkeypatch):&#10;    # Set retries to 2 for a quick test&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '2')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '0')  # No sleep delay&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()  # Mock logger to avoid real logging&#10;    # Mock client.run to always raise Exception&#10;    bot.client.run = mock.Mock(side_effect=Exception('fail'))&#10;    with pytest.raises(Exception):&#10;        bot.run()&#10;    # Should attempt to run 1 initial + 2 retries = 3 times&#10;    assert bot.client.run.call_count == 3&#10;    # Check that error and retry logs were called&#10;    assert bot.logger.error.call_count &gt;= 3&#10;    assert any('Attempting to reconnect' in str(call) for call in bot.logger.info.call_args_list)&#10;&#10;def test_login_failure(monkeypatch):&#10;    from disnake import LoginFailure&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    # Mock client.run to raise LoginFailure&#10;    bot.client.run = mock.Mock(side_effect=LoginFailure('bad token'))&#10;    with pytest.raises(LoginFailure):&#10;        bot.run()&#10;    # Should only try once&#10;    assert bot.client.run.call_count == 1&#10;    assert any('Authentication failed' in str(call) for call in bot.logger.error.call_args_list)&#10;&#10;def test_no_retries(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '0')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '0')&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.run = mock.Mock(side_effect=Exception('fail'))&#10;    with pytest.raises(Exception):&#10;        bot.run()&#10;    # Should only try once (no retries)&#10;    assert bot.client.run.call_count == 1&#10;    assert bot.logger.error.call_count &gt;= 1&#10;&#10;def test_negative_retries(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '-1')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '0')&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.run = mock.Mock(side_effect=Exception('fail'))&#10;    with pytest.raises(Exception):&#10;        bot.run()&#10;    # Class should only try once. Negative retries are treated as 0.&#10;    assert bot.client.run.call_count == 1&#10;    assert bot.logger.error.call_count &gt;= 1&#10;&#10;def test_non_integer_retries(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', 'abc')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '0')&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.run = mock.Mock(side_effect=Exception('fail'))&#10;    with pytest.raises(ValueError):&#10;        bot.run()&#10;&#10;def test_non_integer_delay(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '1')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', 'xyz')&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.run = mock.Mock(side_effect=Exception('fail'))&#10;    with pytest.raises(ValueError):&#10;        bot.run()&#10;&#10;def test_zero_retry_delay(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '2')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '0')&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.run = mock.Mock(side_effect=Exception('fail'))&#10;    # Patch sleep to track calls&#10;    with mock.patch('time.sleep') as mock_sleep:&#10;        with pytest.raises(Exception):&#10;            bot.run()&#10;        # Should attempt to run 1 initial + 2 retries = 3 times&#10;        assert bot.client.run.call_count == 3&#10;        # sleep should not be called since delay is 0&#10;        mock_sleep.assert_not_called()&#10;&#10;def test_retry_succeeds(monkeypatch):&#10;    monkeypatch.setenv('DISCORD_BOT_MAX_RETRIES', '2')&#10;    monkeypatch.setenv('DISCORD_BOT_RETRY_DELAY', '0')&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    # First call fails, second call succeeds&#10;    bot.client.run = mock.Mock(side_effect=[Exception('fail'), None])&#10;    # Should not raise, since the second attempt succeeds&#10;    bot.run()&#10;    assert bot.client.run.call_count == 2&#10;    # Should log error for first failure, but not raise&#10;    assert bot.logger.error.call_count &gt;= 1&#10;&#10;def test_shutdown_exception(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.is_closed = mock.Mock(return_value=False)&#10;    bot.client.close = mock.Mock(side_effect=Exception('shutdown fail'))&#10;    # Patch asyncio to avoid real event loop usage&#10;    with mock.patch('asyncio.get_running_loop', side_effect=RuntimeError()):&#10;        with mock.patch('asyncio.new_event_loop') as mock_new_loop:&#10;            mock_loop = mock.Mock()&#10;            mock_new_loop.return_value = mock_loop&#10;            mock_loop.is_running.return_value = False&#10;            bot.shutdown(loop=mock_loop)&#10;    # Should log the shutdown error&#10;    assert any('shutdown fail' in str(call) for call in bot.logger.error.call_args_list)&#10;&#10;def test_on_ready_sets_connected_and_logs(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    # Simulate event&#10;    asyncio.run(bot.on_ready())&#10;    assert bot.connected is True&#10;    assert any('Connected to Discord as' in str(call) for call in bot.logger.info.call_args_list)&#10;&#10;def test_on_disconnect_sets_disconnected_and_logs(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.connected = True&#10;    asyncio.run(bot.on_disconnect())&#10;    assert bot.connected is False&#10;    assert any('Disconnected from Discord' in str(call) for call in bot.logger.warning.call_args_list)&#10;&#10;def test_on_resumed_sets_connected_and_logs(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.connected = False&#10;    asyncio.run(bot.on_resumed())&#10;    assert bot.connected is True&#10;    assert any('Reconnected to Discord.' in str(call) for call in bot.logger.info.call_args_list)&#10;&#10;class DummyUser:&#10;    def __str__(self):&#10;        return &quot;TestUser&quot;&#10;&#10;def test_on_ready_with_user(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    # Patch client with a mock that has a user property&#10;    class ClientWithUser:&#10;        user = 'TestUser'&#10;    bot.client = ClientWithUser()&#10;    asyncio.run(bot.on_ready())&#10;    assert bot.connected is True&#10;    assert any('Connected to Discord as TestUser' in str(call) for call in bot.logger.info.call_args_list)&#10;&#10;def test_on_disconnect_with_user(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    class ClientWithUser:&#10;        user = 'TestUser'&#10;    bot.client = ClientWithUser()&#10;    bot.connected = True&#10;    asyncio.run(bot.on_disconnect())&#10;    assert bot.connected is False&#10;    assert any('Disconnected from Discord' in str(call) for call in bot.logger.warning.call_args_list)&#10;&#10;def test_on_resumed_with_user(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    class ClientWithUser:&#10;        user = 'TestUser'&#10;    bot.client = ClientWithUser()&#10;    bot.connected = False&#10;    asyncio.run(bot.on_resumed())&#10;    assert bot.connected is True&#10;    assert any('Reconnected to Discord.' in str(call) for call in bot.logger.info.call_args_list)&#10;&#10;def test_run_login_failure_non_mock(monkeypatch):&#10;    from disnake import LoginFailure&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    # Patch client to not be a mock&#10;    class DummyClient:&#10;        def run(self, token):&#10;            raise LoginFailure('bad token')&#10;    bot.client = DummyClient()&#10;    with pytest.raises(LoginFailure):&#10;        bot.run()&#10;    assert any('Authentication failed' in str(call) for call in bot.logger.error.call_args_list)&#10;&#10;def test_shutdown_running_loop_add_done_callback(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.is_closed = mock.Mock(return_value=False)&#10;    async def fake_close():&#10;        # This is a fake coroutine to simulate close&#10;        pass&#10;    coro = fake_close()&#10;    bot.client.close = mock.Mock(return_value=coro)&#10;    # Patch asyncio to avoid real event loop usage&#10;    with mock.patch('asyncio.get_running_loop', side_effect=RuntimeError()):&#10;        with mock.patch('asyncio.new_event_loop') as mock_new_loop:&#10;            mock_loop = mock.Mock()&#10;            mock_new_loop.return_value = mock_loop&#10;            mock_loop.is_running.return_value = True&#10;            # Simulate create_task and add_done_callback&#10;            class DummyTask:&#10;                def add_done_callback(self, cb):&#10;                    cb(self)&#10;            mock_loop.create_task = mock.Mock(return_value=DummyTask())&#10;            bot.shutdown(loop=mock_loop)&#10;    assert any('Bot disconnected gracefully.' in str(call) for call in bot.logger.info.call_args_list)&#10;    coro.close()&#10;&#10;def test_shutdown_returns_if_client_closed(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.is_closed = mock.Mock(return_value=True)&#10;    # Should return early, not call close&#10;    bot.client.close = mock.Mock()&#10;    bot.shutdown()&#10;    bot.client.close.assert_not_called()&#10;&#10;def test_shutdown_returns_if_client_is_mock(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client = mock.Mock()&#10;    bot.client.is_closed.return_value = False&#10;    # Should return early if the client is a mock&#10;    bot.shutdown()&#10;    # Should not call close or log warning&#10;    assert not bot.logger.warning.called&#10;&#10;def test_shutdown_logs_warning_if_close_not_awaitable(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.is_closed = mock.Mock(return_value=False)&#10;    # close returns a non-awaitable&#10;    bot.client.close = mock.Mock(return_value=None)&#10;    # Patch asyncio to avoid real event loop usage&#10;    with mock.patch('asyncio.get_running_loop', side_effect=RuntimeError()):&#10;        with mock.patch('asyncio.new_event_loop') as mock_new_loop:&#10;            mock_loop = mock.Mock()&#10;            mock_new_loop.return_value = mock_loop&#10;            mock_loop.is_running.return_value = False&#10;            bot.shutdown(loop=mock_loop)&#10;    assert any('did not return a coroutine' in str(call) for call in bot.logger.warning.call_args_list)&#10;&#10;def test_shutdown_logs_graceful_disconnect(monkeypatch):&#10;    bot = DiscordBot(token='dummy')&#10;    bot.logger = mock.Mock()&#10;    bot.client.is_closed = mock.Mock(return_value=False)&#10;    async def fake_close():&#10;        # This is a fake coroutine to simulate close&#10;        pass&#10;    coro = fake_close()&#10;    bot.client.close = mock.Mock(return_value=coro)&#10;    # Patch asyncio to avoid real event loop usage&#10;    with mock.patch('asyncio.get_running_loop', side_effect=RuntimeError()):&#10;        with mock.patch('asyncio.new_event_loop') as mock_new_loop:&#10;            mock_loop = mock.Mock()&#10;            mock_new_loop.return_value = mock_loop&#10;            mock_loop.is_running.return_value = False&#10;            # Simulate run_until_complete&#10;            def run_until_complete():&#10;                return None&#10;            mock_loop.run_until_complete = run_until_complete&#10;            bot.shutdown(loop=mock_loop)&#10;    assert any('Bot disconnected gracefully.' in str(call) for call in bot.logger.info.call_args_list)&#10;    coro.close()&#10;&#10;def test_is_connected():&#10;    bot = DiscordBot(token='dummy')&#10;    bot.connected = True&#10;    assert bot.is_connected() is True&#10;    bot.connected = False&#10;    assert bot.is_connected() is False" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>